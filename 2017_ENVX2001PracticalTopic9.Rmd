---
title: "ENVX2001 Practical Topic 9 Variable Selection"
author: "Willem Vervoort"
date: "Document generated on `r Sys.Date()`"
output: 
    pdf_document:
      fig_width: 7
      fig_height: 6
      fig_caption: true
---
```{r setup, warning=F, message=F, echo=F}
# root dir
knitr::opts_knit$set(root.dir = 
                       "z:/willem/teaching/envx2001/otherdata")
library(pander)
library(knitr)
```

# Objectives  

*  Learn to perform PARTIAL F-TESTS in R;
*  Understand the difference between adjusted *r*^2^ and *r*^2^
*  Learn to perform FORWARD SELECTION and BACKWARD ELIMINATION in R.

**DATA**:	*Data_Topic9_2017.xls*

# EXERCISE 1 â€“ MODELLING BIRD ABUNDANCE

Data:  *Loyn2* worksheet, *2017_Loyn2.csv*

This worksheet has 6 predictor variables but note the 3 new names [L10AREA, L10DIST, L10LDIST].  They are the log10 transformed versions of AREA, DIST and LDIST.  Each of these variables was log transformed as they had a small number of larger observations with high leverage.
Import into R using `read.csv()`

Use R for the following analysis

1.	Obtain the correlation between ABUND and all of the 6 predictor variables using `cor()`.  Based on these, what would you expect to be the best single predictor of ABUND?  
2.	Use multiple regression to see whether ABUND can be predicted from L10AREA and GRAZE.  Is there a significant relationship?  Are the assumptions met? We are using these 2 predictors as they have the largest absolute correlations. Use `lm()` and specify the model as `ABUND~L10AREA + GRAZE`.  
3.	How good is the model based on the (i) *r*^2^ (ii) adjusted *r*^2^? Use `summary()`.  
4.	Which variable(s) has the most significant effect(s)? (Refer specifically to the t probabilities in the table of predictors and their estimated parameters or coefficients in the output of `summary()`).  Interpret the p-values in terms of dropping predictor variables.  
5.	Repeat the multiple regression, but this time include YRS.ISOL as a predictor variable (it has the 3rd largest absolute correlation). This will allow you to assess the effect of YRS.ISOL with the other variables taken into account.  Compare the *r*^2^ and adjusted *r*^2^ values with those you calculated for the 2 predictor model.  
6.	Which is the better model?  Why?  

#EXERCISE 2 - PARTIAL F-TESTS IN R 

Data:  *California streamflow worksheet*, *2017_Californiastreamflow.csv*

The following dataset contains 43 years of annual precipitation measurements (in mm) taken at (originally) 6 sites in the Owens Valley in California. I have reduced this to three variables labelled `L10APSAB` (Lake Sabrina), `L10OBPC` (Big Pine Creek), `L10OPRC` (Rock Creek), and the dependent variable stream runoff volume (measured in ML/year) at a site near Bishop, California (labelled `L10BSAAM`). There is also a variable `Year` but you can ignore this.

Note that I have made all the data log10 transformed to increase normality of the residuals in the regressions. 

The purpose is to manually step through FORWARD SELECTION. Remember from the lectures that you basically have two methods of selecting variables: forward and backward. The philosophy behind this is that to fine the best model you can work from these two different directions:

1. start with nothing and slowly add more and more variables, checking everytime whether the addition of a variable actually improves the model.  
2. start with a full model and slowly remove more and more variables, checking everytime whether removal of a variable actually improves the model.  

##(1)	FORWARD SELECTION 
This starts with nothing in the model so the 1st step is to add the most significant predictor variable.  Create a simple linear regression model using `lm()` and `summary()` for each predictor variable and identify the most significant predictor. What measures can you use to determine the most significant predictor? An alternative is to use the correlation matrix, `cor()`, and use the predictor with largest absolute correlation as the starting point.  What does the regression tell you that the correlation matrix (using `cor()`) does not?  
First read in the data.  
```{r readDataStream}
# read in the data
s.data <- read.csv("2017_Californiastreamflow.csv")
names(s.data)
```
```{r Exercise1, eval=F, echo=F}
Mod1 <-lm(L10BSAAM~L10APSAB,data=s.data)
summary(Mod1)
Mod2 <-lm(L10BSAAM~L10OBPC,data=s.data)
summary(Mod2)
Mod3 <-lm(L10BSAAM~L10OPRC,data=s.data)
summary(Mod3)
# you could also run
round(cor(s.data),2)
```
  
##(2) Partial F-Tests
The above analysis should tell that you need `L10OPRC` in the model, what should we add next?  This involves performing **PARTIAL F-TESTS** as discussed in the lecture.  This can be done in **R** by using `anova()` on two model objects. So you have to make objects of all the possible model combinations.  

```{r PartialFtests1, eval=F}
ML.Mod1 <- lm(L10BSAAM~L10OPRC + L10OBPC,data=s.data)
anova(Mod3,ML.Mod1)
```

a. The Regression analysis output gives the test for adding L10OBPC.  
b. The last row gives the results of the partial F-test.  Should we add L10OBPC to the model?  
c. Write out the hypotheses you are testing.  

```{asis, echo=F}
###Solution    
Yes, we should add L10OBPC as the p-value is < 0.05  
The hypothesis   
H~0~: $\beta_{L10OBPC} = 0$  
H~1~: $\beta_{L10OBPC} unequal 0$  
```

Perform a PARTIAL F-TEST to work out if the addition of L10APSAB improves upon the model with just L10OPRC.  

```{r SolutionPartialF, echo=F, eval=F}
ML.Mod2 <- lm(L10BSAAM~L10OPRC + L10APSAB,data=s.data)
anova(Mod3,ML.Mod2)
```

d. Which variable should be added to the model containing L10OPRC?

```{asis, echo=F}  
###Solution  
L10APSAB does not improve the model with only L10OPRC ($\beta_{L10APSAB} = 0$)    
```

##(3) 3 variable model
Based on (2) we either added or did not add an additional predictor to the model with L10OPRC.  If we did not find one of the variables to be significantly improve the single variable model then we stop now.  If you did add a 2nd predictor, then perform a PARTIAL F-TEST to test whether the 3 variable model is superior.  

```{r SolutionThreeVariables, eval=F, echo=F}
ML.Mod3 <- lm(L10BSAAM~L10OPRC + L10OBPC + L10APSAB,data=s.data)
anova(ML.Mod1,ML.Mod3)
```

e. What is your optimal model?

```{asis, echo=F}  
###Solution  
The best model is: $L10BSAAM = \beta_0 + \beta_1 L10OPRC + \beta_2 L10OBPC + error$
```

# EXERCISE 3 - FORWARD SELECTION AND BACKWARD ELIMINATION IN R

Data:  *Dippers* worksheet, *2017_Dippers.csv*

This is dataset we used in the tutorial in Topic 8.  The data has been transformed for some of the variables.  
The file, Breeding density of dippers, gives data from a biological survey which examined the nature of the variables thought to influence the breeding of British dippers (thrush-sized birds living mainly in the upper reaches of rivers; they feed on benthic invertebrates by probing the river beds with their beaks). Twenty two sites were included in the survey. The variables measured were:  

* site altitude
* water hardness
* river-bed slope
* the numbers of caddis fly larvae
* the numbers of stonefly larvae
* the numbers of mayfly larvae
* the numbers of all other invertebrates collected
* the number of breeding pairs of dippers per 10 km of river  

In the analyses, the four invertebrate variables were transformed using a Log(Number+1) transformation.  
```{r readingData}
Dippers <- read.csv("2017_Dippers.csv")
names(Dippers)
```

Using the information on the lecture slides, perform a backward and forward selection starting from a maximal model:  
`MaxMod <- lm(Br_Dens ~ ., data=Dippers)`  
and defining the minimum model as:  
`MinMod <- lm(Br_Dens~1,data=Dippers)`  

Do both approaches identify the same model?  If not, which model would you choose?
To make this easier, assign both the backwards and forwards step analysis to an R object. You should then be able to run `summary()` on the two objects to compare the final models.

```{asis, echo=F}
##Solution
The backward model is he better model, as this has the highest adjusted *r*^2^.
```
```{r VarSelectSolution, echo=F, eval=F}
MaxMod <- lm(Br_Dens ~ ., data=Dippers)
MinMod <- lm(Br_Dens~1,data=Dippers)

# backward selection
backW <- step(MaxMod)
# forward selection
forW <- step(MinMod,scope=formula(MaxMod),direction="forward")
# check which model is best
summary(backW)
summary(forW)
```


